from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain_openai import ChatOpenAI
from langchain_core.prompts import load_prompt, ChatPromptTemplate
from ..tools.rag_tools import LegalRAGTool
from ..validation.response_validator import ResponseValidator
from .base_agent import BaseAgent
from typing import List, Optional
import logging

logger = logging.getLogger(__name__)

class LegalAgent(BaseAgent):
    def __init__(self, index_path: str):
        # LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model_name="gpt-4o",
            temperature=0
        )
        
        # RAG ë„êµ¬ ì´ˆê¸°í™”
        try:
            self.rag_tool = LegalRAGTool(index_path)
        except Exception as e:
            logger.warning(f"LegalRAGTool could not be loaded. Error: {e}")
            self.rag_tool = None
        
        # ê²€ì¦ê¸° ì´ˆê¸°í™”
        self.validator = ResponseValidator()
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
        prompt_data = load_prompt("src/agent/prompts/agentic-rag-prompt-legal.yaml", encoding='utf-8')
        self.prompt_template = prompt_data.template
    
    def run(self, question: str, chat_history: Optional[List] = None) -> str:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if chat_history is None:
            chat_history = []
        
        # chat history í¬ë§·íŒ… - ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€
        formatted_history = []
        for message in chat_history[-5:]:  # ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
            if isinstance(message, dict):
                role = message.get('role', 'user')
                content = message.get('content', '')
                formatted_history.append(f"{role}: {content}")
            else:
                formatted_history.append(f"user: {message}")
        
        max_retries = 0  # ì¬ì‹œë„ íšŸìˆ˜ë¥¼ 0ìœ¼ë¡œ ì„¤ì •
        retry_count = 0
        
        # ë¹„êµ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        is_comparison = self.validator.is_comparison_query(question)
        
        while retry_count <= max_retries:
            logger.info(f"Attempt {retry_count + 1} for question: {question[:50]}...")
            
            # ê²€ìƒ‰ ì „ëµ ì„ íƒ - ë¹„êµ ì§ˆë¬¸ì´ë©´ comparison, ì•„ë‹ˆë©´ ê¸°ë³¸ MMR
            current_strategy = "comparison" if is_comparison else "default"
            logger.info(f"Using search strategy: {current_strategy}")
            
            # RAG ë„êµ¬ê°€ ìˆëŠ” ê²½ìš° ê²€ìƒ‰ ìˆ˜í–‰
            if self.rag_tool:
                try:
                    # vectordb ê²€ìƒ‰ ìˆ˜í–‰
                    search_result = self.rag_tool._run(question, search_strategy=current_strategy, chat_history=chat_history)
                    
                    # ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„± ê²€ì¦
                    search_relevance, search_score = self.validator.validate_search_relevance(question, search_result)
                    logger.info(f"Search validation - Relevance: {search_relevance}, Score: {search_score}")
                    
                    # ê²€ìƒ‰ ê²°ê³¼ê°€ ê´€ë ¨ì„±ì´ ì—†ê³  ì¬ì‹œë„ ê°€ëŠ¥í•œ ê²½ìš°
                    if not search_relevance and retry_count < max_retries:
                        logger.info("Search results not relevant, retrying with different search strategy...")
                        retry_count += 1
                        continue
                    
                    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ chat historyì— ì¶”ê°€
                    formatted_history_with_search = formatted_history.copy()
                    formatted_history_with_search.append(f"assistant: [ğŸ” ìƒˆë¡œ ê²€ìƒ‰ëœ ì°¸ê³  ë¬¸ì„œ]\n{search_result}")

                    # ì‘ë‹µ ìƒì„±
                    try:
                        # í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
                        formatted_prompt = self.prompt_template.format(
                            question=question,
                            chat_history="\n".join(formatted_history_with_search),
                            agent_scratchpad=""
                        )
                        
                        # LLM ì§ì ‘ í˜¸ì¶œ
                        response = self.llm.invoke([{"role": "user", "content": formatted_prompt}])
                        generated_response = response.content
                        
                        # ì‘ë‹µ í’ˆì§ˆ ê²€ì¦
                        response_quality, response_score = self.validator.validate_response_quality(
                            question, search_result, generated_response
                        )
                        logger.info(f"Response validation - Quality: {response_quality}, Score: {response_score}")
                        
                        # ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •
                        should_retry = self.validator.should_retry(
                            search_relevance, search_score,
                            response_quality, response_score,
                            retry_count
                        )
                        
                        if should_retry and retry_count < max_retries:
                            logger.info("Response quality insufficient, retrying with different search strategy...")
                            retry_count += 1
                            continue
                        else:
                            # ìµœì¢… ì‘ë‹µ ë°˜í™˜
                            if not response_quality:
                                logger.warning("Response quality validation failed, but returning response due to retry limit")
                                return f"{generated_response}\n\n[ì°¸ê³ : ì´ ì‘ë‹µì€ ê²€ì¦ ê¸°ì¤€ì„ ì™„ì „íˆ ì¶©ì¡±í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.]"
                            else:
                                return generated_response
                                
                    except Exception as e:
                        logger.error(f"Error in response generation: {e}")
                        if retry_count < max_retries:
                            retry_count += 1
                            continue
                        else:
                            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                except Exception as e:
                    logger.error(f"Error during search: {e}")
                    if retry_count < max_retries:
                        retry_count += 1
                        continue
                    else:
                        return "ì£„ì†¡í•©ë‹ˆë‹¤. ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            else:
                logger.warning("RAG tool is not initialized, cannot perform search.")
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ëª¨ë“  ì¬ì‹œë„ê°€ ì‹¤íŒ¨í•œ ê²½ìš°
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸í•´ì£¼ì„¸ìš”." 